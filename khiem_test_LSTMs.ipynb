{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "khiem_test_LSTMs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnkhiem/course-resources-ml-with-experts-budgets/blob/master/khiem_test_LSTMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg6asGVgzYGZ",
        "colab_type": "code",
        "outputId": "1ce3428e-75c3-40e6-b577-2a838ee9d672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "datalink = 'https://github.com/ttruongatl/ml-lstm/blob/master/data/29297294_02-08-2019.csv'\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://raw.githubusercontent.com/ttruongatl/ml-lstm/master/data/mil-week-labeled-train.csv \\\n",
        "    -O /tmp/mil-week-labeled-train.csv\n",
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-11 03:22:56--  https://raw.githubusercontent.com/ttruongatl/ml-lstm/master/data/mil-week-labeled-train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 95752027 (91M) [text/plain]\n",
            "Saving to: ‘/tmp/mil-week-labeled-train.csv’\n",
            "\n",
            "/tmp/mil-week-label 100%[===================>]  91.32M   156MB/s    in 0.6s    \n",
            "\n",
            "2019-12-11 03:23:01 (156 MB/s) - ‘/tmp/mil-week-labeled-train.csv’ saved [95752027/95752027]\n",
            "\n",
            "Requirement already satisfied: tensorflow==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.8)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.33.6)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.17.4)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0) (42.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.7)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iChnQlNy055k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bSuVkwg0hnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_sentences = 0\n",
        "datetimes = []\n",
        "datas = []\n",
        "labels = []\n",
        "colume = [1,2,3,4,5,6,7,8]\n",
        "header = ['timestamp', 'CylinderBorePressure', 'CylinderRodPressure', 'RotationCWPressure', 'RotationCCWPressure', 'MotionX', 'MotionY', 'MotionZ', 'StringPotV', 'event', 'start']\n",
        "label_dict = {}\n",
        "count = 0\n",
        "with open(\"/tmp/mil-week-labeled-train.csv\") as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "      data = []\n",
        "      for col in colume:\n",
        "        data.append(float(row[col]))\n",
        "      datas.append(data)\n",
        "      datetimes.append(row[0])\n",
        "      labels.append(row[9])\n",
        "      if row[9] not in label_dict:\n",
        "        label_dict[row[9]] = count\n",
        "        count += 1\n",
        "datas = np.array(datas)\n",
        "labels = np.array(list(label_dict[x] for x in labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE-_y1q73nqX",
        "colab_type": "code",
        "outputId": "a7b99605-fb69-458a-8aa5-07d26e339eb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(label_dict)\n",
        "print(datas.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'idle': 0, 'cut': 1, 'sort': 2}\n",
            "(900025, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nfqsVtGLvdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def windowed_dataset(data_in, windows = 20):\n",
        "  data_extend = np.zeros((data_in.shape[0] + windows, data_in.shape[1]))\n",
        "  data_extend[windows:,:] = data_in[:,:]\n",
        "  data_extend = data_extend.T\n",
        "  data_out = np.zeros((data_in.shape[1], data_in.shape[0], windows))\n",
        "  print(data_extend.shape)\n",
        "  print(data_out.shape)\n",
        "  for i in range(data_in.shape[0]):  \n",
        "    data_out[:,i,:] = data_extend[:,i:i+windows]\n",
        "  return data_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBIMRD0fNFSs",
        "colab_type": "code",
        "outputId": "401ccbac-9a1a-4386-97f8-7760aacd2dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "window_size = 40\n",
        "n_samples = 10000\n",
        "\n",
        "datas_new = windowed_dataset(datas, windows = window_size)\n",
        "data_samples = datas_new[:, :n_samples, :] #Get 20 k\n",
        "labels = labels[:n_samples]\n",
        "\n",
        "split_time = int(n_samples *0.8)\n",
        "\n",
        "#max_X = np.max(datas_new)\n",
        "X_train = data_samples[:,:split_time,:]\n",
        "y_train = to_categorical(labels[:split_time])\n",
        "\n",
        "X_valid = data_samples[:,split_time:,:]\n",
        "y_valid = to_categorical(labels[split_time:])\n",
        "\n",
        "\n",
        "X_train = np.transpose(X_train, (1, 2, 0)) / 6000\n",
        "X_valid = np.transpose(X_valid, (1, 2, 0)) / 6000\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_valid.shape)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(8, 900065)\n",
            "(8, 900025, 40)\n",
            "(8000, 40, 8)\n",
            "(2000, 40, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0hwAakgNZXz",
        "colab_type": "code",
        "outputId": "ea5b09fb-100b-4556-93e8-2534fc615235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_valid.shape)\n",
        "np.max(X_train)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 40, 8)\n",
            "(2000, 40, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.867325"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_UTBl2Wp4WM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def separate_block(input_tensor, n_LSTMs = 16, n_Dense = 16):\n",
        "  x = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1))(input_tensor)\n",
        "  x = tf.keras.layers.Conv1D(n_LSTMs, 5, activation = 'relu') (x) # test with Conv1D\n",
        "# x = tf.keras.layers.Dropout(0.2)(x)\n",
        "  x = tf.keras.layers.LSTM(n_LSTMs, return_sequences=True)(x)\n",
        "  x = tf.keras.layers.LSTM(n_LSTMs)(x)\n",
        "  x = tf.keras.layers.Dense(n_Dense, activation=\"relu\")(x)\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iKa1K5SzpCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.99 and logs.get('val_acc')>0.95):\n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTJ5Ua_vNtCK",
        "colab_type": "code",
        "outputId": "cee48e7b-d58b-42f0-a126-d1c53b7c2be8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "#tf.random.set_seed(51)\n",
        "#np.random.seed(51)\n",
        "#window_size = 64\n",
        "#batch_size = 256\n",
        "window_size = 40\n",
        "batch_size = 32\n",
        "epochs = 200\n",
        "callback = myCallback()\n",
        "\n",
        "\n",
        "input_data = tf.keras.layers.Input(shape = [None, 8])\n",
        "print(input_data)\n",
        "\n",
        "x0 = separate_block(input_data[:,:, 0], 32, 32)\n",
        "x1 = separate_block(input_data[:,:, 1], 32, 32)\n",
        "x2 = separate_block(input_data[:,:, 2], 32, 32)\n",
        "x3 = separate_block(input_data[:,:, 3], 32, 32)\n",
        "x4 = separate_block(input_data[:,:, 4], 16, 16)\n",
        "x5 = separate_block(input_data[:,:, 5], 16, 16)\n",
        "x6 = separate_block(input_data[:,:, 6], 16, 16)\n",
        "x7 = separate_block(input_data[:,:, 7], 16, 16)\n",
        "x = tf.keras.layers.concatenate([x0, x1, x2, x3, x4, x5, x6, x7])\n",
        "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dense(3, activation = 'softmax')(x)\n",
        "\n",
        "model = tf.keras.models.Model(input_data, x)\n",
        "\n",
        "#model = tf.keras.models.Sequential([\n",
        "#  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "#                      input_shape=[None]),\n",
        "#  tf.keras.layers.Conv1D(32, 5, activation = 'relu'),  # test with Conv1D\n",
        "#  tf.keras.layers.Dropout(0.2),\n",
        "#  tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "#  tf.keras.layers.LSTM(32),\n",
        "#  tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "#  tf.keras.layers.Dense(3, activation = 'softmax')\n",
        "#])\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=[\"acc\"])\n",
        "history = model.fit(X_train, y_train, epochs=epochs, batch_size= batch_size,\n",
        "                    validation_data=(X_valid, y_valid), verbose = 1, callbacks = [callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"input_1:0\", shape=(None, None, 8), dtype=float32)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 8)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, None)]       0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_1 (Te [(None, None)]       0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_2 (Te [(None, None)]       0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_3 (Te [(None, None)]       0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_4 (Te [(None, None)]       0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_5 (Te [(None, None)]       0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_6 (Te [(None, None)]       0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_7 (Te [(None, None)]       0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, None, 1)      0           tf_op_layer_strided_slice[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, None, 1)      0           tf_op_layer_strided_slice_1[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, None, 1)      0           tf_op_layer_strided_slice_2[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, None, 1)      0           tf_op_layer_strided_slice_3[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, None, 1)      0           tf_op_layer_strided_slice_4[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, None, 1)      0           tf_op_layer_strided_slice_5[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, None, 1)      0           tf_op_layer_strided_slice_6[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, None, 1)      0           tf_op_layer_strided_slice_7[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, None, 32)     192         lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, None, 32)     192         lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, None, 32)     192         lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, None, 32)     192         lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, None, 16)     96          lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, None, 16)     96          lambda_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, None, 16)     96          lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, None, 16)     96          lambda_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, None, 32)     8320        conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, None, 32)     8320        conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   (None, None, 32)     8320        conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   (None, None, 32)     8320        conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   (None, None, 16)     2112        conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_10 (LSTM)                  (None, None, 16)     2112        conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_12 (LSTM)                  (None, None, 16)     2112        conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_14 (LSTM)                  (None, None, 16)     2112        conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           8320        lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 32)           8320        lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   (None, 32)           8320        lstm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   (None, 32)           8320        lstm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_9 (LSTM)                   (None, 16)           2112        lstm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_11 (LSTM)                  (None, 16)           2112        lstm_10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_13 (LSTM)                  (None, 16)           2112        lstm_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_15 (LSTM)                  (None, 16)           2112        lstm_14[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 32)           1056        lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 32)           1056        lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32)           1056        lstm_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           1056        lstm_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 16)           272         lstm_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 16)           272         lstm_11[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 16)           272         lstm_13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 16)           272         lstm_15[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 192)          0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "                                                                 dense_2[0][0]                    \n",
            "                                                                 dense_3[0][0]                    \n",
            "                                                                 dense_4[0][0]                    \n",
            "                                                                 dense_5[0][0]                    \n",
            "                                                                 dense_6[0][0]                    \n",
            "                                                                 dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 128)          24704       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 3)            387         dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 115,011\n",
            "Trainable params: 115,011\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/200\n",
            "8000/8000 [==============================] - 87s 11ms/sample - loss: 0.4640 - acc: 0.8436 - val_loss: 0.3394 - val_acc: 0.8840\n",
            "Epoch 2/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.3366 - acc: 0.8784 - val_loss: 0.3487 - val_acc: 0.8900\n",
            "Epoch 3/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.3135 - acc: 0.8815 - val_loss: 0.3812 - val_acc: 0.8440\n",
            "Epoch 4/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.2919 - acc: 0.8865 - val_loss: 0.3550 - val_acc: 0.8510\n",
            "Epoch 5/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.2681 - acc: 0.8884 - val_loss: 0.4034 - val_acc: 0.8200\n",
            "Epoch 6/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.2314 - acc: 0.9066 - val_loss: 0.3096 - val_acc: 0.8860\n",
            "Epoch 7/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.1884 - acc: 0.9261 - val_loss: 0.3613 - val_acc: 0.8890\n",
            "Epoch 8/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.1689 - acc: 0.9358 - val_loss: 0.3163 - val_acc: 0.8840\n",
            "Epoch 9/200\n",
            "8000/8000 [==============================] - 54s 7ms/sample - loss: 0.1589 - acc: 0.9409 - val_loss: 0.3935 - val_acc: 0.8415\n",
            "Epoch 10/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.1280 - acc: 0.9535 - val_loss: 0.3548 - val_acc: 0.8405\n",
            "Epoch 11/200\n",
            "8000/8000 [==============================] - 54s 7ms/sample - loss: 0.0962 - acc: 0.9670 - val_loss: 0.2646 - val_acc: 0.9035\n",
            "Epoch 12/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.0792 - acc: 0.9728 - val_loss: 0.4376 - val_acc: 0.8225\n",
            "Epoch 13/200\n",
            "8000/8000 [==============================] - 54s 7ms/sample - loss: 0.0692 - acc: 0.9771 - val_loss: 0.3878 - val_acc: 0.8735\n",
            "Epoch 14/200\n",
            "8000/8000 [==============================] - 54s 7ms/sample - loss: 0.0923 - acc: 0.9674 - val_loss: 0.3794 - val_acc: 0.8790\n",
            "Epoch 15/200\n",
            "8000/8000 [==============================] - 54s 7ms/sample - loss: 0.0679 - acc: 0.9765 - val_loss: 0.3213 - val_acc: 0.8830\n",
            "Epoch 16/200\n",
            "8000/8000 [==============================] - 54s 7ms/sample - loss: 0.0340 - acc: 0.9915 - val_loss: 0.4957 - val_acc: 0.8580\n",
            "Epoch 17/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.0393 - acc: 0.9894 - val_loss: 0.3391 - val_acc: 0.9070\n",
            "Epoch 18/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.0989 - acc: 0.9691 - val_loss: 0.8051 - val_acc: 0.7450\n",
            "Epoch 19/200\n",
            "8000/8000 [==============================] - 52s 7ms/sample - loss: 0.0732 - acc: 0.9741 - val_loss: 0.4203 - val_acc: 0.8625\n",
            "Epoch 20/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.0391 - acc: 0.9885 - val_loss: 0.5918 - val_acc: 0.8300\n",
            "Epoch 21/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.0602 - acc: 0.9793 - val_loss: 0.4790 - val_acc: 0.8325\n",
            "Epoch 22/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.0433 - acc: 0.9858 - val_loss: 0.5422 - val_acc: 0.8075\n",
            "Epoch 23/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.0320 - acc: 0.9904 - val_loss: 0.4595 - val_acc: 0.8590\n",
            "Epoch 24/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.0460 - acc: 0.9851 - val_loss: 0.5682 - val_acc: 0.8110\n",
            "Epoch 25/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.0287 - acc: 0.9914 - val_loss: 0.5866 - val_acc: 0.8085\n",
            "Epoch 26/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.0532 - acc: 0.9835 - val_loss: 0.6139 - val_acc: 0.7985\n",
            "Epoch 27/200\n",
            "8000/8000 [==============================] - 52s 7ms/sample - loss: 0.0403 - acc: 0.9861 - val_loss: 0.8520 - val_acc: 0.8010\n",
            "Epoch 28/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.0395 - acc: 0.9875 - val_loss: 0.5392 - val_acc: 0.8480\n",
            "Epoch 29/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.0316 - acc: 0.9908 - val_loss: 0.5107 - val_acc: 0.8160\n",
            "Epoch 30/200\n",
            "8000/8000 [==============================] - 54s 7ms/sample - loss: 0.0699 - acc: 0.9747 - val_loss: 0.6067 - val_acc: 0.8530\n",
            "Epoch 31/200\n",
            "8000/8000 [==============================] - 54s 7ms/sample - loss: 0.0259 - acc: 0.9920 - val_loss: 0.6412 - val_acc: 0.8140\n",
            "Epoch 32/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.0318 - acc: 0.9904 - val_loss: 0.4344 - val_acc: 0.8675\n",
            "Epoch 33/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.0675 - acc: 0.9747 - val_loss: 0.4391 - val_acc: 0.8375\n",
            "Epoch 34/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.0674 - acc: 0.9720 - val_loss: 0.2795 - val_acc: 0.8955\n",
            "Epoch 35/200\n",
            "8000/8000 [==============================] - 52s 7ms/sample - loss: 0.0326 - acc: 0.9886 - val_loss: 0.3484 - val_acc: 0.8910\n",
            "Epoch 36/200\n",
            "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.0475 - acc: 0.9846 - val_loss: 0.5441 - val_acc: 0.8470\n",
            "Epoch 37/200\n",
            "8000/8000 [==============================] - 51s 6ms/sample - loss: 0.0261 - acc: 0.9904 - val_loss: 0.5676 - val_acc: 0.8195\n",
            "Epoch 38/200\n",
            "8000/8000 [==============================] - 52s 6ms/sample - loss: 0.0164 - acc: 0.9958 - val_loss: 0.6161 - val_acc: 0.8275\n",
            "Epoch 39/200\n",
            "7904/8000 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9942"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE8Os9jMmoSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzTvkKaVhXsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}